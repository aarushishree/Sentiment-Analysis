# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iLYsa3tnJhKTR-wSTdAXCiYFz5qnXLeF
"""

!pip install openpyxl nltk wordcloud seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import re
import nltk
from wordcloud import WordCloud
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from collections import Counter

nltk.download('punkt')
nltk.download('stopwords')

file_path = '/content/lgdataset1.xlsx'
xls = pd.ExcelFile(file_path)
print("Sheet names:", xls.sheet_names)

df = xls.parse(xls.sheet_names[0])
df.head()

df.info()

print("\nMissing values:\n", df.isnull().sum())

print("\nSentiment distribution:\n", df['review_text'].value_counts())

import re
def remove_lg(text):
    return re.sub(r'\blg\b', '', text, flags=re.IGNORECASE).strip()

df['clean_text'] = df['clean_text'].apply(remove_lg)

import nltk
nltk.download('punkt_tab')

stop_words = set(stopwords.words('english'))

def clean_text(text):
    if pd.isnull(text):
        return ""
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    text = re.sub(r'\@w+|\#','', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    tokens = word_tokenize(text)
    tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(tokens)


df['clean_text'] = df['review_text'].apply(clean_text)
df[['review_text', 'clean_text']].head()

df['review_length'] = df['review_text'].astype(str).apply(len)
df['word_count'] = df['review_text'].astype(str).apply(lambda x: len(x.split()))

plt.figure(figsize=(12,5))
sns.histplot(df['review_length'], bins=30, kde=True)
plt.title('Distribution of Review Length (characters)')
plt.show()

plt.figure(figsize=(12,5))
sns.histplot(df['word_count'], bins=30, kde=True)
plt.title('Distribution of Word Count')
plt.show()

from collections import Counter

def get_top_n_words(corpus, n=20, exclude_words=None):
    if exclude_words is None:
        exclude_words = []

    words = ' '.join(corpus).split()
    words = [word for word in words if word.lower() not in [w.lower() for w in exclude_words]]
    most_common = Counter(words).most_common(n)
    return pd.DataFrame(most_common, columns=['Word', 'Frequency'])

exclude = ['lg']

top_words_before = get_top_n_words(df['review_text'].dropna(), exclude_words=exclude)
top_words_after = get_top_n_words(df['clean_text'], exclude_words=exclude)

print("Top words before cleaning:\n", top_words_before)
print("\nTop words after cleaning:\n", top_words_after)

from wordcloud import WordCloud
import matplotlib.pyplot as plt

text = ' '.join(df['clean_text'])
text = ' '.join(word for word in text.split() if word.lower() != 'lg')

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("WordCloud of Cleaned Reviews (without 'lg')")
plt.show()

from sklearn.feature_extraction.text import CountVectorizer
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

def plot_ngrams(corpus, ngram_range=(2,2), n=20, exclude_words=None):
    if exclude_words is None:
        exclude_words = []

    vec = CountVectorizer(ngram_range=ngram_range, stop_words='english').fit(corpus)
    bag_of_words = vec.transform(corpus)
    sum_words = bag_of_words.sum(axis=0)
    words_freq = [
        (word, sum_words[0, idx])
        for word, idx in vec.vocabulary_.items()
        if not any(ex_word.lower() in word.lower().split() for ex_word in exclude_words)
    ]
    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)[:n]
    df_ngrams = pd.DataFrame(words_freq, columns=['N-gram', 'Frequency'])

    plt.figure(figsize=(10, 5))
    sns.barplot(x='Frequency', y='N-gram', data=df_ngrams)
    plt.title(f"Top {n} {'-'.join(map(str, ngram_range))} N-grams )")
    plt.tight_layout()
    plt.show()

# Call with "lg" excluded
plot_ngrams(df['clean_text'], ngram_range=(2,2), exclude_words=['lg'])

!pip install vaderSentiment

import pandas as pd
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()
def get_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'
df['vader_score'] = df['clean_text'].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])
df['vader_sentiment'] = df['vader_score'].apply(get_sentiment)

df[['clean_text', 'vader_score', 'vader_sentiment']].head()

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=df, x='vader_sentiment')
plt.title("VADER Sentiment Distribution")
plt.show()

df['review_length'] = df['review_text'].astype(str).apply(lambda x: len(x.split()))

sns.barplot(x='vader_sentiment', y='review_length', data=df, estimator=np.mean, ci=None)
plt.title("Average Review Length by Sentiment")
plt.xlabel("Sentiment")
plt.ylabel("Average Length")
plt.show()

import matplotlib.pyplot as plt

def plot_top_words(word_freq, sentiment):
    words, freqs = zip(*word_freq)
    plt.figure(figsize=(8, 4))
    sns.barplot(x=list(freqs), y=list(words), palette='viridis')
    plt.title(f"Top Words in {sentiment} Reviews")
    plt.xlabel("Frequency")
    plt.ylabel("Words")
    plt.tight_layout()
    plt.show()

plot_top_words(top_pos, "Positive")
plot_top_words(top_neg, "Negative")
plot_top_words(top_neu, "Neutral")

df.to_csv("vader_labeled_reviews1.csv")

!pip install textblob openpyxl

from textblob import TextBlob
import pandas as pd

df = pd.read_excel("/content/lgdataset1.xlsx")
vader_df = pd.read_csv("/content/vader_labeled_reviews1.csv")
df = pd.merge(df, vader_df[['review_text', 'vader_sentiment']], on='review_text', how='left')
df.rename(columns={'YourColumnName': 'review_text'}, inplace=True)

df.dropna(subset=['review_text'], inplace=True)

def get_textblob_sentiment(text):
    blob = TextBlob(str(text))
    polarity = blob.sentiment.polarity
    subjectivity = blob.sentiment.subjectivity

    if polarity > 0.05:
        sentiment = 'Positive'
    elif polarity < -0.05:
        sentiment = 'Negative'
    else:
        sentiment = 'Neutral'

    return pd.Series([polarity, subjectivity, sentiment])

df[['tb_polarity', 'tb_subjectivity', 'tb_sentiment']] = df['review_text'].apply(get_textblob_sentiment)
df[['review_text', 'tb_polarity', 'tb_subjectivity', 'tb_sentiment']].head()

output_path = "textblob_sentiment_reviews.xlsx"
df.to_excel(output_path, index=False)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('/content/vader_labeled_reviews1.csv')
df = df[['review_text', 'vader_sentiment']]
df.dropna(inplace=True)

import re

def clean_text(text):
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"[^a-zA-Z\s']", "", text)
    text = text.lower()
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df['clean_text'] = df['review_text'].apply(clean_text)

X = df['clean_text']
y = df['vader_sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

sns.countplot(x=y)
plt.title("Class Balance for ML Model")
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2))
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X_vec = vectorizer.fit_transform(X)

print("TF-IDF matrix shape:", X_vec.shape)

from sklearn.naive_bayes import MultinomialNB
nb_model = MultinomialNB()
nb_model.fit(X_train_vec, y_train)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
y_pred = nb_model.predict(X_test_vec)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:")
print(cm)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_excel('/content/textblob_sentiment_reviews.xlsx')
df = df[['review_text', 'tb_sentiment']]
df.dropna(inplace=True)
df.head()

import re

def clean_text(text):
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"[^A-Za-z\s]", "", text)
    text = text.lower()
    return text

df['clean_text'] = df['review_text'].apply(clean_text)

X = df['clean_text']
y = df['tb_sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = CountVectorizer(stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

nb_model = MultinomialNB()
nb_model.fit(X_train_vec, y_train)

y_pred = nb_model.predict(X_test_vec)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.linear_model import LogisticRegression

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(ngram_range=(1,2))
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

log_reg_model = LogisticRegression(max_iter=1000)
log_reg_model.fit(X_train_vec, y_train)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

vectorizer = TfidfVectorizer(ngram_range=(1,2))
X_vec = vectorizer.fit_transform(X)
X_train_vec, X_test_vec, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)

log_reg_model = LogisticRegression(max_iter=1000)
log_reg_model.fit(X_train_vec, y_train)

y_pred = log_reg_model.predict(X_test_vec)

print("Accuracy:", accuracy_score(y_test, y_pred))

print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:\n", cm)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

df = pd.read_csv('/content/vader_labeled_reviews1.csv')

df.dropna(subset=['review_text', 'vader_sentiment'], inplace=True)

X = df['review_text']
y = df['vader_sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

svm_model = LinearSVC()
svm_model.fit(X_train_vec, y_train)

y_pred = svm_model.predict(X_test_vec)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

df = pd.read_csv('/content/vader_labeled_reviews1.csv')
df.dropna(subset=['review_text', 'vader_sentiment'], inplace=True)

X = df['review_text']
y = df['vader_sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_vec, y_train)

y_pred = rf_model.predict(X_test_vec)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, accuracy_score

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

rfc = RandomForestClassifier(random_state=42)
grid_search_rf = GridSearchCV(rfc, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)
grid_search_rf.fit(X_train_vec, y_train)

best_rf = grid_search_rf.best_estimator_
y_pred_rf = best_rf.predict(X_test_vec)

print("Accuracy:", accuracy_score(y_test, y_pred_rf))

print("\n Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
df = pd.read_csv('/content/vader_labeled_reviews1.csv')
df.dropna(subset=['review_text', 'vader_sentiment'], inplace=True)
X = df['review_text']
y = df['vader_sentiment']
vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb_model.fit(X_train_vec.toarray(), y_train)
y_pred = gb_model.predict(X_test_vec.toarray())
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 6, 10],
    'learning_rate': [0.01, 0.1, 0.3],
    'subsample': [0.8, 1.0]
}

le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
grid_search_xgb = GridSearchCV(xgb, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)
grid_search_xgb.fit(X_train_vec, y_train_encoded)

best_xgb = grid_search_xgb.best_estimator_
y_pred_xgb = best_xgb.predict(X_test_vec)
print("XGBoost Classification Report:")
print(classification_report(y_test_encoded, y_pred_xgb, target_names=le.classes_))

print("Accuracy:", accuracy_score(y_test, y_pred))

pip install transformers torch scikit-learn

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv("/content/vader_labeled_reviews1.csv")
df_clean = df.dropna(subset=['clean_text'])
df_binary = df_clean[df_clean['vader_sentiment'].isin(['Positive', 'Negative'])].copy()
le = LabelEncoder()
df_binary['label'] = le.fit_transform(df_binary['vader_sentiment'])
train_texts, test_texts, train_labels, test_labels = train_test_split(
    df_binary['clean_text'].tolist(),
    df_binary['label'].tolist(),
    test_size=0.2,
    stratify=df_binary['label'],
    random_state=42
)

from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)
test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)

import torch

class ReviewDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} | {'labels': torch.tensor(self.labels[idx])}

    def __len__(self):
        return len(self.labels)

train_dataset = ReviewDataset(train_encodings, train_labels)
test_dataset = ReviewDataset(test_encodings, test_labels)

from transformers import BertForSequenceClassification, Trainer, TrainingArguments

model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=4,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=10,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
    save_total_limit=2
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset
)

trainer.train()

from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
pred_outputs = trainer.predict(test_dataset)
pred_labels = np.argmax(pred_outputs.predictions, axis=1)
acc = accuracy_score(test_labels, pred_labels)
f1 = f1_score(test_labels, pred_labels, average='weighted')

print(f"Accuracy: {acc * 100:.2f}%")
print(f"F1 Score: {f1:.4f}")
cm = confusion_matrix(test_labels, pred_labels)
labels = ['Negative', 'Positive']

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()
print("Classification Report:")
print(classification_report(test_labels, pred_labels, target_names=labels))

import matplotlib.pyplot as plt

models = ['Naive Bayes', 'Logistic Regression', 'SVM', 'Random Forest', 'Gradient Boosting', 'BERT']
accuracies = [0.6557377049180327, 0.6639344262295082, 0.6885245901639344, 0.6967213114754098, 0.6721311475409836, 0.7692307692307693]

plt.figure(figsize=(10,6))
plt.bar(models, accuracies, color='lightblue')
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.xticks(rotation=30)
plt.show()